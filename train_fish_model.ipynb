{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train kaggle fish model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tranfer learning model build upon InceptionV3 for the competition\n",
    "\n",
    "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring\n",
    "\n",
    "The kaggle data is downloaded to data/train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Conv2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "def create_dir_if_not_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Move files into train and test folder ##\n",
    "from shutil import copyfile\n",
    "import os\n",
    "if False:    \n",
    "    %rm data/train -r\n",
    "    %rm data/validation -r\n",
    "    train_ratio = 0.7\n",
    "    raw_path = 'data/raw/'\n",
    "    train_path = 'data/train/'\n",
    "    val_path = 'data/validation/'\n",
    "\n",
    "    categories = os.listdir(raw_path)\n",
    "\n",
    "    for cat in categories:\n",
    "        create_dir_if_not_exist(train_path+cat)\n",
    "        create_dir_if_not_exist(val_path+cat)\n",
    "\n",
    "        images = os.listdir(raw_path+cat)\n",
    "        for im in images:\n",
    "            if np.random.rand() < train_ratio:\n",
    "                copyfile(raw_path+cat+\"/\"+im, train_path+cat+\"/\"+im)\n",
    "            else:\n",
    "                copyfile(raw_path+cat+\"/\"+im, val_path+cat+\"/\"+im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "## ADD FINAL LAYER\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DATA GENERATOR ###\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "        )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size = (299,299),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'data/validation/',\n",
    "    target_size = (299,299),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TEST ONE PICTURE ##\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "im = load_img('data/train/ALB/img_00029.jpg')\n",
    "imshow(im)\n",
    "img_to_array(im).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, epsilon = 0.01,\n",
    "                  patience=2, min_lr=0.00001, verbose = 1)\n",
    "\n",
    "#checkpoint = ModelCheckpoint(\"model_checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", \n",
    "#                             monitor=['val_loss','accuracy'])\n",
    "\n",
    "csv_logger = CSVLogger(\"training.log\", separator=',', append=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our new layers while freezing the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "    validation_data = validation_generator,\n",
    "    samples_per_epoch=2000,\n",
    "    nb_val_samples = 500,\n",
    "    nb_epoch=5,\n",
    "    callbacks = [reduce_lr,checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train more layers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "    validation_data = validation_generator,\n",
    "    samples_per_epoch=2000,\n",
    "    nb_val_samples = 500,\n",
    "    nb_epoch=5,\n",
    "    callbacks = [reduce_lr,checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_path = 'data/test_stg1/'\n",
    "test_images = os.listdir(test_path)\n",
    "\n",
    "preds = list()\n",
    "names = list()\n",
    "for im in test_images:\n",
    "    x = img_to_array(load_img(test_path+im,target_size=(299, 299)))\n",
    "    x = np.expand_dims(x, axis=0)/255.\n",
    "    r = model.predict(x)\n",
    "    names.append(im)\n",
    "    preds.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classPreds = pd.DataFrame(np.concatenate(preds), \n",
    "                          columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT']).clip(0.2,0.8)\n",
    "classPreds['image'] = names\n",
    "\n",
    "arrCol = ['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT']\n",
    "\n",
    "classPreds[arrCol].to_csv(\"submission_clipped.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
